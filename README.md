# Sistema RAG (Retrieval-Augmented Generation)

Un sistema completo de RAG para anÃ¡lisis de documentos Markdown que combina bÃºsqueda vectorial con generaciÃ³n de respuestas mediante IA.

## ğŸ“‹ Ãndice

- [ğŸš€ CaracterÃ­sticas Principales](#-caracterÃ­sticas-principales)
- [ğŸ› ï¸ InstalaciÃ³n](#ï¸-instalaciÃ³n)
- [ğŸ“– GuÃ­a de Uso de Comandos](#-guÃ­a-de-uso-de-comandos)
  - [ğŸ”„ Comandos Principales](#-comandos-principales-mutuamente-exclusivos)
  - [ğŸ”§ Opciones Complementarias](#-opciones-complementarias)
  - [ğŸ’¡ Ejemplos PrÃ¡cticos](#-ejemplos-prÃ¡cticos-de-combinaciones)
  - [âš ï¸ Restricciones Importantes](#ï¸-restricciones-importantes)
  - [ğŸ¯ Casos de Uso TÃ­picos](#-casos-de-uso-tÃ­picos)
- [ğŸŒ Interfaz Web y Chatbot](#-interfaz-web-y-chatbot)
- [ğŸ—ï¸ Arquitectura del Sistema](#ï¸-arquitectura-del-sistema)
  - [ğŸ“ Estructura del Proyecto](#-estructura-del-proyecto)
  - [ğŸ”„ Flujo de Datos](#-flujo-de-datos)
  - [ğŸ”— InteracciÃ³n de Componentes](#-interacciÃ³n-de-componentes)
- [ğŸ”§ ExtensiÃ³n del Sistema](#-extensiÃ³n-del-sistema)
  - [â• Agregar Nuevo Cliente IA](#-agregar-nuevo-cliente-ia)
  - [ğŸ—„ï¸ Agregar Nueva Base de Datos](#ï¸-agregar-nueva-base-de-datos)
  - [âœ‚ï¸ Agregar Nuevo MÃ©todo de Chunking](#ï¸-agregar-nuevo-mÃ©todo-de-chunking)
  - [ğŸ“Š Agregar Nuevo Modelo de Embeddings](#-agregar-nuevo-modelo-de-embeddings)
- [âš™ï¸ ConfiguraciÃ³n](#ï¸-configuraciÃ³n)
  - [ğŸ›ï¸ ConfiguraciÃ³n Global (config.yaml)](#ï¸-configuraciÃ³n-global-configyaml)
  - [ğŸ”‘ Variables de Entorno](#-variables-de-entorno)
  - [ğŸ“ ConfiguraciÃ³n por MÃ³dulos](#-configuraciÃ³n-por-mÃ³dulos)
- [ğŸ“š DocumentaciÃ³n de MÃ³dulos](#-documentaciÃ³n-de-mÃ³dulos)
- [ğŸ”— Enlaces Ãštiles](#-enlaces-Ãºtiles)
- [ğŸ¤ Contribuciones](#-contribuciones)
- [ğŸ“„ Licencia](#-licencia)

## ğŸš€ CaracterÃ­sticas Principales

- **ğŸ“„ Procesamiento de documentos**: Ingesta y procesa archivos Markdown con chunking inteligente y optimizaciÃ³n de memoria
- **ğŸ” BÃºsqueda vectorial**: Encuentra informaciÃ³n relevante usando embeddings semÃ¡nticos con mÃºltiples algoritmos de similitud
- **ğŸ¤– MÃºltiples modelos IA**: Compatible con OpenAI, Google Gemini y Ollama con configuraciÃ³n unificada
- **ğŸ—„ï¸ Bases de datos vectoriales**: Soporte para SQLite y DuckDB con optimizaciones especÃ­ficas y bÃºsqueda eficiente
- **ğŸ’¾ GestiÃ³n de recursos**: Monitoreo automÃ¡tico de memoria y CPU con limpieza inteligente y concurrencia adaptativa
- **ğŸ’¬ Modo interactivo**: Interfaz conversacional para consultas continuas con historial y comandos especiales
- **ğŸŒ Interfaz web**: Chatbot web integrado para acceso fÃ¡cil y amigable al sistema
- **ğŸ“Š GestiÃ³n de sesiones**: Sistema unificado para organizar proyectos y bases de datos con metadatos completos
- **âš¡ OptimizaciÃ³n de rendimiento**: Procesamiento paralelo, batching dinÃ¡mico y liberaciÃ³n automÃ¡tica de recursos

## ğŸ› ï¸ InstalaciÃ³n

### Requisitos del Sistema

- **Python 3.8 o superior**
- **8GB RAM mÃ­nimo** (16GB recomendado para documentos grandes)
- **2GB espacio libre** para modelos y bases de datos

### InstalaciÃ³n RÃ¡pida

1. **Clonar el repositorio:**
```bash
git clone <repository-url>
cd dof-rag
```

2. **Crear entorno virtual:**
```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# o
.venv\Scripts\activate     # Windows
```

3. **Instalar dependencias:**
```bash
# El proyecto usa pyproject.toml para gestiÃ³n de dependencias
pip install -e .

# O instalaciÃ³n alternativa si hay problemas:
pip install -r requirements.txt
```

4. **Configurar variables de entorno:**
```bash
cp .env-example .env
# Editar .env con tus API keys (ver secciÃ³n Variables de Entorno)
```

5. **Verificar instalaciÃ³n:**
```bash
python run.py --resource-status
```

## ğŸ“– GuÃ­a de Uso de Comandos

### ğŸ”„ Comandos Principales (Mutuamente Exclusivos)

Estos comandos definen el **modo de operaciÃ³n** del sistema. Solo puedes usar uno a la vez:

#### **ğŸ“¥ Modo Ingesta** (`--ingest`)
Procesa documentos Markdown y los almacena en la base de datos vectorial.

```bash
# Crear nueva sesiÃ³n/base de datos
python run.py --ingest --files documentos/

# Agregar documentos a base de datos existente
python run.py --ingest --files nuevos_docs/ --db-index 0

# Crear sesiÃ³n con nombre personalizado
python run.py --ingest --files documentos/ --session-name "mi_proyecto"

# Procesar archivo Ãºnico
python run.py --ingest --files documento.md

# Procesamiento con debug activado
python run.py --ingest --files documentos/ --debug
```

**CaracterÃ­sticas del modo ingesta:**
- **Procesamiento recursivo**: Busca archivos `.md` en subdirectorios
- **OptimizaciÃ³n de memoria**: Procesamiento streaming para documentos grandes
- **Transacciones atÃ³micas**: Rollback automÃ¡tico si hay errores
- **Concurrencia adaptativa**: ParalelizaciÃ³n inteligente segÃºn recursos
- **Metadatos completos**: ExtracciÃ³n de tÃ­tulos, encabezados y estructura

#### **ğŸ” Modo Consulta** (`--query`)
Realiza bÃºsquedas y genera respuestas basadas en los documentos procesados.

```bash
# Consulta Ãºnica
python run.py --query "Â¿CuÃ¡l es el tema principal del documento?"

# Modo interactivo (sin texto de consulta)
python run.py --query

# Consulta con parÃ¡metros especÃ­ficos
python run.py --query "Mi pregunta" --chunks 10 --db-index 2

# Consulta con modelo especÃ­fico
python run.py --query "Explica el proceso" --model gemini --chunks 8

# Mostrar bases disponibles antes de consultar
python run.py --query "Mi pregunta" --show-dbs
```

**CaracterÃ­sticas del modo consulta:**
- **BÃºsqueda semÃ¡ntica**: RecuperaciÃ³n basada en similitud vectorial
- **Contexto enriquecido**: CombinaciÃ³n inteligente de fragmentos relevantes
- **MÃºltiples modelos**: Soporte para OpenAI, Gemini, Ollama
- **Respuestas contextuales**: Basadas Ãºnicamente en documentos procesados
- **Tiempo de respuesta**: MediciÃ³n y optimizaciÃ³n automÃ¡tica

#### **ğŸ“‹ GestiÃ³n y Mantenimiento**
```bash
# Listar sesiones/bases de datos disponibles
python run.py --list-sessions

# Mostrar estadÃ­sticas detalladas de bases de datos
python run.py --db-stats

# Optimizar base de datos especÃ­fica
python run.py --optimize-db 0

# Optimizar todas las bases de datos
python run.py --optimize-all

# Ver estado del gestor de recursos
python run.py --resource-status
```

### ğŸ”§ Opciones Complementarias

Estas opciones **se pueden combinar** con los comandos principales:

#### **ğŸ“¤ Exportar Chunks** (`--export-chunks`)
Exporta los fragmentos procesados a archivos de texto para revisiÃ³n y anÃ¡lisis.

```bash
# Solo exportar (requiere documentos ya procesados)
python run.py --export-chunks --files documentos/

# âœ¨ Combinar: Procesar Y exportar en un solo comando
python run.py --ingest --export-chunks --files documentos/

# Exportar con base de datos especÃ­fica
python run.py --export-chunks --files documentos/ --db-index 1
```

**Formato de exportaciÃ³n:**
- **Archivos .txt**: Un archivo por documento original
- **Estructura preservada**: Encabezados y metadatos incluidos
- **NumeraciÃ³n de chunks**: Fragmentos numerados secuencialmente
- **InformaciÃ³n tÃ©cnica**: Dimensiones de embeddings y mÃ©tricas

#### **ğŸ¯ Opciones de Consulta Avanzadas**
```bash
# Especificar nÃºmero de fragmentos a recuperar (1-20)
--chunks 10

# Usar modelo IA especÃ­fico  
--model gemini|openai|ollama

# Usar sesiÃ³n especÃ­fica por ID
--session mi_sesion_20241220_142030

# Usar base de datos por Ã­ndice (mÃ¡s rÃ¡pido)
--db-index 2

# Mostrar bases disponibles antes de consultar
--show-dbs
```

#### **ğŸ› DepuraciÃ³n y Monitoreo**
```bash
# Modo debug (logs detallados)
--debug

# Combinado con procesamiento para anÃ¡lisis detallado
python run.py --ingest --files test/ --debug
```

### ğŸ’¡ Ejemplos PrÃ¡cticos de Combinaciones

#### **ğŸ—ï¸ Flujo Completo: Procesar + Exportar**
```bash
# Procesa documentos Y exporta chunks en un solo paso
python run.py --ingest --export-chunks --files mis_documentos/
```

#### **ğŸ” Consultas Avanzadas**
```bash
# Consulta con configuraciÃ³n especÃ­fica
python run.py --query "Explica el proceso de instalaciÃ³n" \
  --chunks 8 \
  --db-index 1 \
  --debug

# Consulta mostrando bases disponibles primero
python run.py --query "Mi pregunta" --show-dbs

# Comparar respuestas entre modelos
python run.py --query "Mismo concepto" --model openai --db-index 0
python run.py --query "Mismo concepto" --model gemini --db-index 0
```

#### **ğŸ“Š Mantenimiento Integral**
```bash
# 1. Ver estado actual del sistema
python run.py --resource-status

# 2. Ver sesiones disponibles
python run.py --list-sessions

# 3. Optimizar base especÃ­fica
python run.py --optimize-db 0

# 4. Ver estadÃ­sticas actualizadas  
python run.py --db-stats
```

#### **ğŸ”„ GestiÃ³n de Proyectos**
```bash
# 1. Crear proyecto nuevo
python run.py --ingest --files proyecto_alpha/ --session-name "Proyecto Alpha"

# 2. Ver bases disponibles
python run.py --list-sessions

# 3. Agregar nuevos documentos al proyecto
python run.py --ingest --files nuevos_documentos/ --db-index 0

# 4. Consultar el proyecto actualizado
python run.py --query "Resumen del proyecto" --db-index 0
```

### âš ï¸ Restricciones Importantes

1. **Un solo comando principal**: No puedes usar `--ingest` y `--query` juntos
2. **Archivos requeridos**: `--ingest` y `--export-chunks` requieren `--files`
3. **Prioridad de bases**: `--db-index` tiene prioridad sobre `--session`
4. **LÃ­mites de chunks**: MÃ¡ximo 20 chunks por consulta (configuraciÃ³n ajustable)
5. **Formatos soportados**: Solo archivos `.md` (Markdown)

### ğŸ¯ Casos de Uso TÃ­picos

| Escenario | Comando |
|-----------|---------|
| **Primera vez** | `python run.py --ingest --files docs/` |
| **Consulta rÃ¡pida** | `python run.py --query "mi pregunta"` |  
| **Modo interactivo** | `python run.py --query` |
| **Agregar documentos** | `python run.py --ingest --files nuevos/ --db-index 0` |
| **Revisar chunks** | `python run.py --export-chunks --files docs/` |
| **Proceso completo** | `python run.py --ingest --export-chunks --files docs/` |
| **Mantenimiento** | `python run.py --optimize-all && python run.py --db-stats` |
| **AnÃ¡lisis de recursos** | `python run.py --resource-status` |

## ğŸŒ Interfaz Web y Chatbot

### Chatbot Web Integrado

El sistema incluye una interfaz web moderna para interactuar con el RAG de manera intuitiva:

#### **CaracterÃ­sticas del Chatbot**
- **Interfaz moderna**: DiseÃ±o responsive y amigable
- **SelecciÃ³n de bases**: Cambio dinÃ¡mico entre proyectos/sesiones
- **Historial de conversaciÃ³n**: Mantiene contexto de la sesiÃ³n
- **Streaming de respuestas**: Respuestas en tiempo real
- **Indicadores visuales**: Estado de procesamiento y errores
- **ExportaciÃ³n**: Descarga de conversaciones

#### **EjecuciÃ³n del Chatbot**
```bash
# Iniciar servidor web (puerto 8000 por defecto)
python -m http.server 8000 --directory web/

# Acceder en navegador
# http://localhost:8000
```

#### **ConfiguraciÃ³n del Chatbot**
```javascript
// web/config.js
const config = {
    apiUrl: 'http://localhost:5000',  // URL del API RAG
    defaultChunks: 5,
    models: ['gemini', 'openai', 'ollama'],
    theme: 'auto'  // 'light', 'dark', 'auto'
};
```

#### **API Endpoints**
```bash
# Listar sesiones disponibles
GET /api/sessions

# Realizar consulta
POST /api/query
{
    "query": "Mi pregunta",
    "db_index": 0,
    "chunks": 5,
    "model": "gemini"
}

# Estado del sistema
GET /api/status
```

### IntegraciÃ³n con Aplicaciones Externas

```python
# Ejemplo de integraciÃ³n Python
import requests

def consultar_rag(pregunta, db_index=0):
    response = requests.post('http://localhost:5000/api/query', json={
        'query': pregunta,
        'db_index': db_index,
        'chunks': 5
    })
    return response.json()

resultado = consultar_rag("Â¿CÃ³mo instalar el sistema?")
print(resultado['response'])
```

## ğŸ—ï¸ Arquitectura del Sistema

### ğŸ“ Estructura del Proyecto

```
ğŸ“ new_rag/
â”œâ”€â”€ ğŸ”§ modulos/                    # Componentes principales del sistema
â”‚   â”œâ”€â”€ ğŸ“š chunks/                 # Procesamiento de fragmentos
â”‚   â”‚   â”œâ”€â”€ ChunkerFactory.py      # Factory para chunkers
â”‚   â”‚   â””â”€â”€ implementaciones/      
â”‚   â”‚       â”œâ”€â”€ character_chunker.py    # Por caracteres
â”‚   â”‚       â”œâ”€â”€ token_chunker.py        # Por tokens (recomendado)
â”‚   â”‚       â”œâ”€â”€ context_chunker.py      # Por contexto semÃ¡ntico
â”‚   â”‚       â””â”€â”€ page_chunker.py         # Por pÃ¡ginas
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ¤– clientes/               # Clientes IA
â”‚   â”‚   â”œâ”€â”€ AbstractClient.py      # Interfaz base
â”‚   â”‚   â”œâ”€â”€ FactoryClient.py       # Factory pattern
â”‚   â”‚   â””â”€â”€ implementaciones/      
â”‚   â”‚       â”œâ”€â”€ openai.py          # Cliente OpenAI
â”‚   â”‚       â”œâ”€â”€ gemini.py          # Cliente Google Gemini  
â”‚   â”‚       â””â”€â”€ ollama.py          # Cliente Ollama (local)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ—„ï¸ databases/             # Bases de datos vectoriales
â”‚   â”‚   â”œâ”€â”€ VectorialDatabase.py   # Interfaz base
â”‚   â”‚   â”œâ”€â”€ FactoryDatabase.py     # Factory pattern
â”‚   â”‚   â””â”€â”€ implementaciones/
â”‚   â”‚       â”œâ”€â”€ sqlite.py          # SQLite con sqlite-vec
â”‚   â”‚       â””â”€â”€ duckdb.py          # DuckDB (recomendado)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“Š embeddings/             # Modelos de embeddings
â”‚   â”‚   â”œâ”€â”€ embeddings_factory.py  # Factory para embeddings
â”‚   â”‚   â””â”€â”€ implementaciones/
â”‚   â”‚       â”œâ”€â”€ modernbert.py      # ModernBERT (recomendado)
â”‚   â”‚       â”œâ”€â”€ e5_small.py        # E5-small multilingÃ¼e
â”‚   â”‚       â””â”€â”€ cde_small.py       # CDE-small
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ doc_processor/          # Procesamiento de documentos
â”‚   â”‚   â””â”€â”€ markdown_processor.py  # Procesador Markdown
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ¯ session_manager/        # GestiÃ³n de sesiones
â”‚   â”‚   â””â”€â”€ session_manager.py     # GestiÃ³n unificada
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ’¾ resource_management/    # GestiÃ³n de recursos
â”‚   â”‚   â”œâ”€â”€ resource_manager.py    # Gestor principal
â”‚   â”‚   â””â”€â”€ memory_manager.py      # GestiÃ³n de memoria
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ–¼ï¸ view_chunks/            # ExportaciÃ³n y visualizaciÃ³n
â”‚   â”‚   â””â”€â”€ chunk_exporter.py      # Exportador de chunks
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ› ï¸ utils/                 # Utilidades del sistema
â”‚       â”œâ”€â”€ formatting.py          # Formateo de output
â”‚       â””â”€â”€ logging_utils.py       # ConfiguraciÃ³n de logs
â”‚
â”œâ”€â”€ ğŸŒ web/                        # Interfaz web del chatbot
â”‚   â”œâ”€â”€ index.html                 # PÃ¡gina principal
â”‚   â”œâ”€â”€ config.js                  # ConfiguraciÃ³n del frontend
â”‚   â”œâ”€â”€ styles.css                 # Estilos CSS
â”‚   â””â”€â”€ app.js                     # LÃ³gica JavaScript
â”‚
â”œâ”€â”€ âš™ï¸ config.yaml                 # ConfiguraciÃ³n principal
â”œâ”€â”€ ğŸš€ run.py                      # Punto de entrada CLI
â”œâ”€â”€ ğŸ“‹ main.py                     # LÃ³gica principal del sistema
â”œâ”€â”€ ğŸ”§ config.py                   # GestiÃ³n de configuraciÃ³n
â”œâ”€â”€ ğŸ“¦ pyproject.toml              # ConfiguraciÃ³n del proyecto
â”œâ”€â”€ ğŸ“„ requirements.txt            # Dependencias (alternativo)
â””â”€â”€ ğŸ“ sessions/                   # AlmacÃ©n de sesiones
    â””â”€â”€ metadata/                  # Metadatos de sesiones
```

### ğŸ”„ Flujo de Datos

#### **Ingesta de Documentos**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ğŸ“„ .md     â”‚â”€â”€â”€â–ºâ”‚ ğŸ” MarkdownProc â”‚â”€â”€â”€â–ºâ”‚ âœ‚ï¸ Chunker  â”‚â”€â”€â”€â–ºâ”‚ ğŸ“Š EmbeddingMod â”‚â”€â”€â”€â–ºâ”‚ ğŸ—„ï¸ Database â”‚
â”‚   Files      â”‚    â”‚   - Metadata    â”‚    â”‚ - Strategy  â”‚    â”‚ - Vectorization â”‚    â”‚ - Storage   â”‚
â”‚              â”‚    â”‚   - Headers     â”‚    â”‚ - Overlap   â”‚    â”‚ - Normalization â”‚    â”‚ - Indexing  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **Procesamiento de Consultas**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â“ Query    â”‚â”€â”€â”€â–ºâ”‚ ğŸ“Š EmbeddingMod â”‚â”€â”€â”€â–ºâ”‚ ğŸ” VectorSearch â”‚â”€â”€â”€â–ºâ”‚ ğŸ¤– IAClient â”‚â”€â”€â”€â–ºâ”‚ ğŸ’¬ Response â”‚
â”‚ - Text      â”‚    â”‚ - Vectorization â”‚    â”‚ - Similarity    â”‚    â”‚ - Context   â”‚    â”‚ - Streaming â”‚
â”‚ - Intent    â”‚    â”‚ - Normalization â”‚    â”‚ - Top-K         â”‚    â”‚ - Generate  â”‚    â”‚ - Formatted â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”— InteracciÃ³n de Componentes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Chunking Module    â”‚     â”‚ Embedding Module   â”‚     â”‚   Database Module   â”‚
â”‚  ---------------    â”‚     â”‚ ---------------    â”‚     â”‚   ---------------   â”‚
â”‚  - Character        â”‚     â”‚  - ModernBERT      â”‚     â”‚   - SQLite          â”‚
â”‚  - Token            â”‚â—„â”€â”€â”€â”€â”¤  - CDE             â”œâ”€â”€â”€â”€â–ºâ”‚   - DuckDB          â”‚
â”‚  - Context          â”‚     â”‚  - E5              â”‚     â”‚                     â”‚
â”‚  - Page             â”‚     â”‚                    â”‚     â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–²                          â–²                           â–²
          â”‚                          â”‚                           â”‚
          â”‚                          â”‚                           â”‚
          â”‚                          â–¼                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Resource Management â”‚     â”‚   IA Clients       â”‚     â”‚  Session Manager  â”‚
â”‚------------------  â”‚     â”‚   ------------     â”‚     â”‚  --------------   â”‚
â”‚- ResourceManager   â”‚â—„â”€â”€â”€â–ºâ”‚   - OpenAI         â”‚â—„â”€â”€â”€â–ºâ”‚  - User Sessions  â”‚
â”‚- MemoryManager     â”‚     â”‚   - Gemini         â”‚     â”‚  - Conversations  â”‚
â”‚- ConcurrencyManagerâ”‚     â”‚   - Ollama         â”‚     â”‚  - Context Storageâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–²                          â–²                           â–²
          â”‚                          â”‚                           â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚   Configuration    â”‚
                           â”‚   ------------     â”‚
                           â”‚   - config.yaml    â”‚
                           â”‚   - .env           â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ ExtensiÃ³n del Sistema

### â• Agregar Nuevo Cliente IA

#### **1. Crear ImplementaciÃ³n**

```python
# modulos/clientes/implementaciones/mi_cliente.py
from ..AbstractClient import IAClient
from typing import List, Dict, Any, Optional

class MiClienteIA(IAClient):
    def __init__(self, api_key: str = None, **kwargs):
        """Inicializar cliente con configuraciÃ³n especÃ­fica"""
        # Tu implementaciÃ³n especÃ­fica
        pass
    
    def generate_response(self, prompt: str, context: List[Dict] = None, **kwargs) -> str:
        """Generar respuesta usando tu API/modelo"""
        # Implementar lÃ³gica de generaciÃ³n
        pass
    
    def get_embedding(self, text: str) -> List[float]:
        """Generar embeddings si el cliente lo soporta"""
        # Opcional: implementar si tu cliente maneja embeddings
        pass
```

#### **2. Registrar en Factory**

```python
# modulos/clientes/FactoryClient.py
def get_client(client_type: str, **kwargs) -> IAClient:
    # ...existing code...
    elif client_type == 'mi_cliente':
        from modulos.clientes.implementaciones.mi_cliente import MiClienteIA
        return MiClienteIA(**params)
```

#### **3. Configurar en config.yaml**

```yaml
# config.yaml
ai_client:
  mi_cliente:
    model: "mi_modelo_v1"
    api_key_env: "MI_CLIENTE_API_KEY"
    api_url: "https://mi-api.com/v1"
    timeout: 30
    # ParÃ¡metros especÃ­ficos de tu cliente
    temperatura_custom: 0.8
```

#### **4. Configurar Variables de Entorno**

```bash
# .env
MI_CLIENTE_API_KEY=tu_api_key_aqui
```

### ğŸ—„ï¸ Agregar Nueva Base de Datos

#### **1. Implementar Interfaz**

```python
# modulos/databases/implementaciones/mi_db.py
from modulos.databases.VectorialDatabase import VectorialDatabase
from typing import List, Dict, Any

class MiBaseDatos(VectorialDatabase):
    def __init__(self, embedding_dim: int):
        self.embedding_dim = embedding_dim
        # Tu implementaciÃ³n especÃ­fica
    
    def connect(self, db_path: str) -> bool:
        """Conectar a tu base de datos"""
        pass
    
    def vector_search(self, query_embedding: List[float], n_results: int = 5) -> List[Dict]:
        """Implementar bÃºsqueda vectorial especÃ­fica"""
        pass
    
    def insert_document(self, document: Dict[str, Any], chunks: List[Dict]) -> int:
        """Insertar documento con chunks"""
        pass
    
    def optimize_database(self) -> bool:
        """Optimizar tu base de datos"""
        pass
```

#### **2. Registrar en Factory**

```python
# modulos/databases/FactoryDatabase.py
def get_database_instance(db_type: str, embedding_dim: int):
    # ...existing code...
    elif db_type == "mi_db":
        from .implementaciones.mi_db import MiBaseDatos
        return MiBaseDatos(embedding_dim=embedding_dim)
```

#### **3. Configurar en config.yaml**

```yaml
# config.yaml
database:
  type: "mi_db"
  mi_db:
    connection_string: "mi://localhost:5432/rag_db"
    pool_size: 10
    timeout: 30
    similarity_threshold: 0.3
```

### âœ‚ï¸ Agregar Nuevo MÃ©todo de Chunking

#### **1. Implementar Chunker**

```python
# modulos/chunks/implementaciones/mi_chunker.py
from typing import Generator, Dict, Any, List
from modulos.chunks.AbstractChunker import AbstractChunker

class MiChunker(AbstractChunker):
    def __init__(self, modelo_embedding, **kwargs):
        super().__init__(modelo_embedding)
        # ConfiguraciÃ³n especÃ­fica
        self.chunk_strategy = kwargs.get('strategy', 'semantic')
    
    def process_content_stream(self, content: str, doc_title: str = "") -> Generator[Dict[str, Any], None, None]:
        """Generar chunks usando tu estrategia especÃ­fica"""
        # Implementar lÃ³gica de chunking
        for chunk in self._tu_logica_chunking(content):
            yield {
                'text': chunk['texto'],
                'header': chunk.get('encabezado', ''),
                'page': chunk.get('pagina', ''),
                'metadata': chunk.get('metadatos', {})
            }
    
    def _tu_logica_chunking(self, content: str) -> List[Dict]:
        """Tu algoritmo especÃ­fico de chunking"""
        pass
```

#### **2. Registrar en Factory**

```python
# modulos/chunks/ChunkerFactory.py
def get_chunker(chunker_type: str, embedding_model):
    # ...existing code...
    elif chunker_type == "mi_chunker":
        from .implementaciones.mi_chunker import MiChunker
        return MiChunker(embedding_model, **config)
```

#### **3. Configurar en config.yaml**

```yaml
# config.yaml
chunks:
  method: "mi_chunker"
  mi_chunker:
    strategy: "semantic"
    max_chunk_size: 1500
    overlap_ratio: 0.1
    preserve_structure: true
```

### ğŸ“Š Agregar Nuevo Modelo de Embeddings

#### **1. Implementar Modelo**

```python
# modulos/embeddings/implementaciones/mi_embedding.py
from modulos.embeddings.AbstractEmbedding import AbstractEmbedding
from typing import List

class MiModeloEmbedding(AbstractEmbedding):
    def __init__(self, **kwargs):
        self.model_name = kwargs.get('model_name', 'mi-modelo-v1')
        self.dimensions = kwargs.get('dimensions', 768)
        # Inicializar tu modelo
    
    def get_dimensions(self) -> int:
        return self.dimensions
    
    def get_document_embedding(self, header: str, text: str) -> List[float]:
        """Generar embedding para documento"""
        combined_text = f"{header}\n{text}" if header else text
        return self._generate_embedding(combined_text)
    
    def get_query_embedding(self, query: str) -> List[float]:
        """Generar embedding para consulta"""
        return self._generate_embedding(query)
    
    def _generate_embedding(self, text: str) -> List[float]:
        """Tu implementaciÃ³n especÃ­fica"""
        pass
```

#### **2. Registrar en Factory**

```python
# modulos/embeddings/embeddings_factory.py
def get_embedding_manager(model_type: str):
    # ...existing code...
    elif model_type == "mi_embedding":
        from .implementaciones.mi_embedding import MiModeloEmbedding
        return MiModeloEmbedding(**config)
```

#### **3. Configurar en config.yaml**

```yaml
# config.yaml
embeddings:
  model: "mi_embedding"
  mi_embedding:
    model_name: "mi-empresa/mi-modelo-v1"
    dimensions: 1024
    device: "cuda"
    normalize: true
    batch_size: 16
```

## âš™ï¸ ConfiguraciÃ³n

### ğŸ›ï¸ ConfiguraciÃ³n Global (config.yaml)

El sistema utiliza un archivo de configuraciÃ³n centralizado `config.yaml` que controla todos los aspectos del funcionamiento. Esta configuraciÃ³n sigue un patrÃ³n jerÃ¡rquico que permite especificaciones generales y especÃ­ficas por mÃ³dulo.

#### **ğŸ—ï¸ Estructura de ConfiguraciÃ³n**

```yaml
# ConfiguraciÃ³n general del sistema
general:
  debug: false                    # Modo debug global
  log_level: "INFO"              # Nivel de logging
  log_dir: "logs"                # Directorio de logs
  sessions_dir: "sessions"       # Directorio de sesiones

# ConfiguraciÃ³n especÃ­fica por mÃ³dulo
ai_client:
  type: "gemini"                 # Cliente por defecto
  general:                       # ConfiguraciÃ³n compartida
    temperature: 0.7
    max_tokens: 2048
    system_prompt: "..."
  gemini:                        # ConfiguraciÃ³n especÃ­fica
    model: "gemini-2.0-flash"
    api_key_env: "GEMINI_API_KEY"

embeddings:
  model: "modernbert"            # Modelo por defecto
  modernbert:
    model_name: "nomic-ai/modernbert-embed-base"
    device: "cpu"
    normalize: true

database:
  type: "duckdb"                # Base de datos por defecto
  duckdb:
    memory_limit: "2GB"
    threads: 4
    similarity_threshold: 0.3

chunks:
  method: "token"               # MÃ©todo de chunking por defecto
  token:
    max_tokens: 2048
    token_overlap: 100
    tokenizer: "nomic-ai/modernbert-embed-base"

resource_management:
  monitoring:
    interval_sec: 120           # Intervalo de monitoreo
    aggressive_threshold_mem_pct: 85
  memory:
    auto_suspend_memory_mb: 1000
  concurrency:
    cpu_workers: "auto"         # DetecciÃ³n automÃ¡tica
    io_workers: "auto"
```

#### **ğŸ”„ JerarquÃ­a de ConfiguraciÃ³n**

1. **ConfiguraciÃ³n general**: Valores aplicables a todos los mÃ³dulos
2. **ConfiguraciÃ³n especÃ­fica**: Valores especÃ­ficos por implementaciÃ³n
3. **Variables de entorno**: Sobrescriben configuraciÃ³n del archivo
4. **ParÃ¡metros de lÃ­nea de comandos**: MÃ¡xima prioridad

#### **ğŸ¯ Configuraciones Clave**

**Rendimiento y Recursos:**
```yaml
resource_management:
  monitoring:
    aggressive_threshold_mem_pct: 85  # Umbral memoria crÃ­tica
    warning_threshold_mem_pct: 75     # Umbral advertencia
  concurrency:
    cpu_workers: "auto"               # Workers automÃ¡ticos
    max_total_workers: null           # Sin lÃ­mite por defecto
  memory:
    model_release:
      inactive_timeout_sec: 300       # Liberar modelos inactivos
```

**Calidad de Respuestas:**
```yaml
ai_client:
  general:
    temperature: 0.7                  # Balance creatividad/precisiÃ³n
    top_p: 0.85                       # Diversidad de respuestas
    top_k: 50                         # Vocabulario permitido
    system_prompt: "..."              # Instrucciones del sistema
processing:
  max_chunks_to_retrieve: 5           # Contexto por consulta
```

**OptimizaciÃ³n de Memoria:**
```yaml
chunks:
  memory_optimization:
    enabled: true                     # Habilitar optimizaciÃ³n
    batch_size: 50                    # TamaÃ±o de lote base
    memory_check_interval: 15         # VerificaciÃ³n cada 15s
    force_gc: true                    # Garbage collection forzado
```

### ğŸ”‘ Variables de Entorno

Las variables de entorno tienen prioridad sobre `config.yaml` y permiten configuraciÃ³n sensible sin exposer secretos:

```bash
# .env
# APIs principales
OPENAI_API_KEY=sk-tu_openai_key_aqui
GEMINI_API_KEY=tu_gemini_key_aqui
OLLAMA_API_URL=http://localhost:11434

# APIs adicionales
ANTHROPIC_API_KEY=tu_anthropic_key_aqui

# ConfiguraciÃ³n de desarrollo
RAG_DEBUG_MODE=true
RAG_LOG_LEVEL=DEBUG

# ConfiguraciÃ³n de base de datos
RAG_DB_TYPE=duckdb
RAG_DB_PATH=/custom/path/to/db

# ConfiguraciÃ³n de recursos
RAG_MEMORY_LIMIT=8GB
RAG_CPU_WORKERS=4
```

#### **ğŸ”§ Acceso a ConfiguraciÃ³n desde CÃ³digo**

```python
from config import config

# Obtener configuraciÃ³n completa
full_config = config.get_config()

# Obtener configuraciÃ³n especÃ­fica
ai_config = config.get_ai_client_config()
db_config = config.get_database_config()
embed_config = config.get_embedding_config()

# Obtener configuraciÃ³n filtrada para un cliente especÃ­fico
gemini_config = config.get_specific_ai_config('gemini')
```

### ğŸ“ ConfiguraciÃ³n por MÃ³dulos

#### **ğŸ¤– Clientes IA**
- **ParÃ¡metros generales**: Compartidos entre todos los clientes
- **ConfiguraciÃ³n especÃ­fica**: Por proveedor (OpenAI, Gemini, Ollama)
- **Manejo de APIs**: Variables de entorno para claves
- **Timeouts y reintentos**: ConfiguraciÃ³n de robustez

#### **ğŸ“Š Embeddings**
- **SelecciÃ³n de modelo**: ModernBERT, E5-small, CDE-small
- **ConfiguraciÃ³n de dispositivo**: CPU/CUDA/MPS
- **ParÃ¡metros de normalizaciÃ³n**: Para consistencia vectorial
- **OptimizaciÃ³n de memoria**: Batch processing

#### **ğŸ—„ï¸ Bases de Datos**
- **Tipo de BD**: SQLite vs DuckDB
- **ConfiguraciÃ³n de memoria**: LÃ­mites y optimizaciÃ³n
- **ParalelizaciÃ³n**: NÃºmero de threads
- **Umbrales de similitud**: Para bÃºsqueda vectorial

#### **âœ‚ï¸ Chunking**
- **MÃ©todo de fragmentaciÃ³n**: Token, carÃ¡cter, contexto
- **OptimizaciÃ³n de memoria**: Procesamiento streaming
- **ConfiguraciÃ³n de solapamiento**: Para continuidad
- **ExtracciÃ³n de metadatos**: Encabezados y estructura

## ğŸ“š DocumentaciÃ³n de MÃ³dulos

### ğŸ“– DocumentaciÃ³n Detallada

- **[ğŸ› ï¸ GuÃ­a del Desarrollador](DEVELOPER_GUIDE.md)** - DocumentaciÃ³n tÃ©cnica completa para desarrolladores. Incluye configuraciÃ³n del entorno de desarrollo, arquitectura del sistema, APIs internas, patrones de diseÃ±o, estrategias de testing y debugging, y guÃ­as paso a paso para contribuir al proyecto.

- **[ğŸ¯ Session Manager](modulos/session_manager/README.md)** - DocumentaciÃ³n del gestor de sesiones que coordina el acceso a bases de datos del sistema RAG. Cubre la gestiÃ³n unificada de sesiones=bases de datos, comandos para listar y gestionar sesiones, casos de uso comunes, y troubleshooting especÃ­fico.

- **[ğŸ’¾ Resource Management](modulos/resource_management/README.md)** - DocumentaciÃ³n del sistema centralizado para gestiÃ³n inteligente de recursos (memoria, CPU, concurrencia). Explica el monitoreo automÃ¡tico, gestiÃ³n de modelos de embedding, configuraciÃ³n de umbrales, y optimizaciÃ³n de rendimiento.

### ğŸ”§ APIs Internas

Cada mÃ³dulo implementa el **patrÃ³n Factory** para creaciÃ³n de instancias:

- **ğŸ¤– Clientes IA**: `modulos/clientes/FactoryClient.py` - Abstracciones unificadas para OpenAI, Gemini, Ollama con manejo consistente de errores y configuraciÃ³n
- **ğŸ“Š Embeddings**: `modulos/embeddings/embeddings_factory.py` - GestiÃ³n de modelos ModernBERT, E5, CDE-small con optimizaciÃ³n de memoria y dispositivo
- **ğŸ—„ï¸ Bases de Datos**: `modulos/databases/FactoryDatabase.py` - Implementaciones SQLite y DuckDB con bÃºsqueda vectorial optimizada y transacciones ACID
- **âœ‚ï¸ Chunking**: `modulos/chunks/ChunkerFactory.py` - Procesamiento por tokens, caracteres, contexto con streaming y preservaciÃ³n de metadatos
- **ğŸ“„ Procesamiento**: `modulos/doc_processor/markdown_processor.py` - AnÃ¡lisis de documentos Markdown con extracciÃ³n de estructura y metadatos

## ğŸ”— Enlaces Ãštiles

- **[âš™ï¸ ConfiguraciÃ³n Principal](config.yaml)** - Archivo de configuraciÃ³n centralizado con todas las opciones del sistema, parÃ¡metros de modelos, umbrales de recursos, y configuraciones especÃ­ficas por mÃ³dulo

- **[ğŸ”‘ Variables de Entorno](.env-example)** - Plantilla de configuraciÃ³n para APIs y variables sensibles. Incluye ejemplos para OpenAI, Gemini, Ollama y configuraciones de desarrollo

- **[ğŸ“ MÃ³dulos del Sistema](modulos/)** - Directorio principal con toda la implementaciÃ³n modular. Cada subdirectorio contiene componentes especÃ­ficos con documentaciÃ³n propia y ejemplos de uso

- **[ğŸŒ Interfaz Web](web/)** - Chatbot web integrado con interfaz moderna, selecciÃ³n dinÃ¡mica de bases de datos, historial de conversaciones y streaming de respuestas

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas y valoradas. El proyecto sigue estÃ¡ndares de cÃ³digo abierto:

### ğŸ“‹ Proceso de ContribuciÃ³n

1. **Fork** el repositorio en tu cuenta
2. **Crear rama** de feature: `git checkout -b feature/nueva-funcionalidad`
3. **Desarrollar** usando los comandos de debugging: `python run.py --debug`
4. **Testear** extensivamente: `python run.py --ingest --files test_docs/ --debug`
5. **Documentar** cambios en READMEs correspondientes
6. **Commit** con mensajes descriptivos: `git commit -m "feat: nueva funcionalidad X"`
7. **Push** a tu fork: `git push origin feature/nueva-funcionalidad`
8. **Pull Request** con descripciÃ³n detallada y pruebas

### ğŸ¯ Ãreas de ContribuciÃ³n

- **ğŸ”Œ Nuevos clientes IA**: Anthropic, Cohere, clientes locales
- **ğŸ—„ï¸ Bases de datos**: PostgreSQL+pgvector, Qdrant, Weaviate
- **ğŸ“Š Modelos de embedding**: Nuevos modelos de HuggingFace
- **âœ‚ï¸ MÃ©todos de chunking**: Chunking semÃ¡ntico, por entidades
- **ğŸŒ Interfaz web**: Mejoras UX, nuevas funcionalidades
- **ğŸ“š DocumentaciÃ³n**: Tutoriales, ejemplos, casos de uso

### ğŸ“ EstÃ¡ndares de CÃ³digo

- **Type hints** obligatorios para funciones pÃºblicas
- **Docstrings** estilo Google para documentaciÃ³n
- **Logging** apropiado con niveles consistentes
- **Tests** para nuevas funcionalidades
- **ConfiguraciÃ³n** centralizada en `config.yaml`
- **Manejo de errores** robusto con logging detallado

Para desarrollo detallado, consulta la **[ğŸ› ï¸ GuÃ­a del Desarrollador](DEVELOPER_GUIDE.md)** que incluye:
- ConfiguraciÃ³n completa del entorno de desarrollo
- Arquitectura interna y patrones de diseÃ±o
- Comandos especÃ­ficos de testing y debugging
- GuÃ­as paso a paso para agregar nuevos componentes
- EstÃ¡ndares de cÃ³digo y mejores prÃ¡cticas

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la **licencia MIT**. Ver archivo `LICENSE` para detalles completos.

### Resumen de la Licencia
- âœ… **Uso comercial** permitido
- âœ… **ModificaciÃ³n** permitida  
- âœ… **DistribuciÃ³n** permitida
- âœ… **Uso privado** permitido
- â— **Sin garantÃ­a** - el software se proporciona "como estÃ¡"
- ğŸ“‹ **AtribuciÃ³n requerida** - incluir aviso de copyright