# Configuración general del sistema RAG
general:
  # Modo de depuración (activa logs más detallados)
  debug: false
  # Directorio para almacenar logs
  log_dir: "logs"
  # Directorio para almacenar sesiones
  sessions_dir: "sessions"
  # Nivel de logging (DEBUG, INFO, WARNING, ERROR)
  log_level: "INFO"

# Configuración para chunking de documentos
chunks:
  # Método de chunking a utilizar (character, token, context, page)
  method: "page" 
  
  # Formato de encabezado por defecto (standard, simple)
  # standard: Formato detallado con encabezados Markdown
  # simple: Formato simple tipo "Documento - Página X - Encabezado"
  header_format: "simple"
  
  # Configuración para memoria y procesamiento
  memory_optimization:
    # Habilitar optimización de memoria (procesamiento de chunks uno por uno)
    enabled: true
    # Tamaño de lote para proceso de chunks antes de forzar gc
    batch_size: 50
    # Forzar garbage collection periódicamente
    force_gc: true
    # Monitorear uso de memoria
    memory_monitor: true
  
  # Configuración para chunker por caracteres
  character:
    # Tamaño máximo del chunk en caracteres
    chunk_size: 1000
    # Solapamiento entre chunks en caracteres
    chunk_overlap: 200
    # Habilitar o deshabilitar extracción de encabezados (puede mejorar rendimiento)
    header_extraction_enabled: true
    # Longitud mínima para considerar un texto como encabezado
    min_header_length: 1
    # Longitud máxima para un encabezado (textos más largos se saltan para mejorar rendimiento)
    max_header_length: 6
    # Formato de encabezado específico para este método (opcional)
    header_format: "simple"
  
  # Configuración para chunker por tokens
  token:
    # Nombre del modelo de tokenizador (debe ser compatible con HF)
    # tokenizer: "intfloat/multilingual-e5-small"
    tokenizer: "nomic-ai/modernbert-embed-base"
    # Cantidad máxima de tokens por chunk
    max_tokens: 2048
    # Solapamiento entre chunks en tokens
    token_overlap: 100
    # Formato de encabezado específico para este método (opcional)
    header_format: "standard"
  
  # Configuración para chunker por contexto
  context:
    # Utilizar encabezados para dividir chunks
    use_headers: true
    # Nivel máximo de encabezado para separar (1=H1, 2=H2, etc.)
    max_header_level: 6
    # Tamaño máximo de texto por chunk
    max_chunk_size: 1500
    # Formato de encabezado específico para este método (opcional)
    header_format: "standard"
    
  # Configuración para chunker por páginas
  page:
    # Utilizar encabezados para mejorar el contexto
    use_headers: true
    # Nivel máximo de encabezado a considerar
    max_header_level: 6
    # Patrón de expresión regular para identificar marcadores de página
    page_pattern: '\{(\d+)\}\s*-{5,}'
    # Formato de encabezado específico para este método (opcional)
    header_format: "simple"

# Configuración para generación de embeddings
embeddings:
  # Modelo de embedding a utilizar (modernbert, cde-small, e5-small)
  model: "modernbert"
  # Incluir parámetro para trust_remote_code
  trust_remote_code: True
  
  # Configuración para ModernBERT
  modernbert:
    # Nombre completo del modelo
    model_name: "nomic-ai/modernbert-embed-base"
    # Dispositivo para inferencia (cpu, cuda, mps)
    device: "cpu"
    # Normalizar embeddings para similitud por coseno
    normalize: true
    # Longitud máxima de tokens para el modelo
    max_length: 512
    batch_size: 32
  
  # Configuración para CDE-small
  cde-small:
    model_name: "jxm/cde-small-v2"
    normalize: true
    max_length: 384
    batch_size: 32
  
  # Configuración para E5-small
  e5-small:
    model_name: "intfloat/multilingual-e5-small"
    normalize: true
    max_length: 512
    batch_size: 32
    prefix_queries: true
    prefix_passages: true

# Configuración de la base de datos
database:
  # Tipo de base de datos (sqlite, duckdb, ...)
  type: "sqlite"
  
  # Configuración para SQLite
  sqlite:
    # Ruta al archivo de base de datos
    db_dir: "modulos/databases/db"
    db_name: ""  # Nombre vacío para que siempre se genere automáticamente
    similarity_threshold: 0.3
    # Habilitar extensión sqlite-vec para búsqueda vectorial optimizada
    use_vector_extension: true
  
  # Configuración para DuckDB
  duckdb:
    # Ruta al archivo de base de datos
    db_dir: "modulos/databases/db"
    db_name: ""  # Nombre vacío para que siempre se genere automáticamente
    similarity_threshold: 0.3
    # Límite de memoria para operaciones de DuckDB (2GB por defecto)
    memory_limit: "2GB"
    # Número de hilos para procesamiento paralelo (4 es un valor seguro para la mayoría de sistemas)
    threads: 4
    # Extensiones a instalar (httpfs, json)
    extensions: ["httpfs", "json"]

# Configuración para clientes de IA
ai_client:
  # Tipo de cliente por defecto (openai, gemini, ollama)
  type: "gemini"
  
  # Parámetros generales para modelos de IA (aplicables a todos los modelos)
  general:
    # Prompt inicial de sistema
    system_prompt: "Eres un asistente preciso especializado en responder preguntas basándote únicamente en la información proporcionada. Tu objetivo es analizar cuidadosamente el contexto y extraer respuestas relevantes sin añadir información externa. Responde SIEMPRE en español, usando un tono claro y profesional. Si la información proporcionada no es suficiente para responder a la pregunta, indícalo claramente sin intentar adivinar. Prioriza la precisión sobre la creatividad, asegurándote de que cada afirmación pueda ser respaldada por el contexto proporcionado. El formato en el que recibiras el contexto los es en markdown, responde del mejor formato para que el usuario pueda leerlo, no markdown."
    
    # Parámetros optimizados para RAG (aplicables a todos los modelos)
    # Temperatura baja para favorecer respuestas factuales y precisas
    temperature: 0.4
    # Tokens máximos para la respuesta
    max_tokens: 2048
    # Top-p para muestreo (nucleus sampling)
    top_p: 0.65
    # Top-k para diversidad controlada
    top_k: 35
    # Utilizar streaming (tiempo-real) para respuestas
    stream: false
    # Formato de respuesta
    response_mime_type: "text/plain"
    # Instrucciones para el formateo de contexto
    context_format: "fragments"  # options: fragments, simple, numbered
    # Estilo de formateo de instrucciones
    instruction_style: "detailed"  # options: minimal, detailed, standard
  
  # Configuración específica para OpenAI (solo lo específico de la plataforma)
  openai:
    # Modelo a utilizar
    model: "gpt-3.5-turbo"
    # Nombre de la variable de entorno para la API key
    api_key_env: "OPENAI_API_KEY"
    # Nombre de la variable de entorno para la URL base de la API (opcional)
    api_base_env: "OPENAI_API_BASE"
    # Modelo para embeddings
    embedding_model: "text-embedding-ada-002"
    # Parámetros únicos para OpenAI (que no estén en general)
    frequency_penalty: 0.0
    presence_penalty: 0.0
    timeout: 30
  
  # Configuración específica para Gemini
  gemini:
    # Modelo a utilizar
    model: "gemini-2.0-flash"
    # Nombre de la variable de entorno para la API key
    api_key_env: "GEMINI_API_KEY"
    # Modelo para embeddings
    embedding_model: "embedding-001"
  
  # Configuración específica para Ollama
  ollama:
    # Modelo a utilizar
    model: "gemma2:4b"
    # URL de la API
    api_url: "http://localhost:11434/api"
    # Nombre de la variable de entorno para la URL de la API (opcional)
    api_url_env: "OLLAMA_API_URL"
    # Modelo para embeddings
    embedding_model: "all-minilm"
    # Timeout específico para Ollama
    timeout: 60

# Parámetros para procesamiento de documentos
processing:
  # Número máximo de chunks a recuperar para cada consulta
  max_chunks_to_retrieve: 5

# Configuración para el Gestor de Recursos Centralizado
resource_management:
  # Intervalo en segundos para el monitoreo de recursos
  monitoring_interval: 30
  # Umbral de porcentaje de uso de memoria para acciones de limpieza agresivas
  aggressive_threshold_memory: 85
  # Umbral de porcentaje de uso de memoria para advertencias o limpieza normal
  warning_threshold_memory: 75
  # Umbral de porcentaje de uso de CPU para advertencias
  warning_threshold_cpu: 80
  # Habilitar/deshabilitar el hilo de monitoreo del ResourceManager
  monitoring_enabled: true
  # Nivel de verbosidad para los logs de ResourceManager
  # minimal: Solo errores y advertencias importantes
  # normal: Información básica y advertencias (por defecto)
  # detailed: Información detallada, útil para diagnóstico
  log_verbosity: "minimal"
  
  # Configuración para ConcurrencyManager (se usará en Fase 4)
  concurrency:
    # Número de workers por defecto para tareas intensivas en CPU.
    # Puede ser un valor fijo, "auto" (basado en cores), o ajustado dinámicamente.
    default_cpu_workers: "auto" # Ejemplo: 'auto' podría significar os.cpu_count()
    # Número de workers por defecto para tareas I/O bound.
    default_io_workers: "auto" # Ejemplo: min(32, (os.cpu_count() or 1) + 4)
    # Máximo de workers global si se desea limitar.
    max_total_workers: null # null o un entero para un límite superior