# Chat RAG - Sistema de Consulta DOF

Sistema de chat inteligente que permite consultar documentos del **Diario Oficial de la FederaciÃ³n (DOF)** mediante tecnologÃ­a **RAG (Retrieval-Augmented Generation)**. Utiliza bÃºsqueda semÃ¡ntica para encontrar informaciÃ³n relevante y genera respuestas contextuales respaldadas por fuentes especÃ­ficas.

## Â¿QuÃ© hace?

**ConversaciÃ³n inteligente con documentos oficiales**: Haz preguntas en lenguaje natural y obtÃ©n respuestas precisas extraÃ­das directamente de documentos del DOF, con referencias a las fuentes utilizadas.

**Ejemplo de uso:**
- Pregunta: *"Â¿QuÃ© decretos relacionados con infraestructura se publicaron en enero 2025?"*
- Respuesta: InformaciÃ³n especÃ­fica con enlaces a documentos exactos del DOF

## âœ¨ CaracterÃ­sticas Principales

- ğŸ¤– **Chat conversacional** con historial de preguntas y respuestas
- ï¿½ **BÃºsqueda semÃ¡ntica** en base de datos vectorial de documentos DOF
- ï¿½ **Fuentes verificables** con fragmentos exactos y enlaces a documentos
- âš™ï¸ **ConfiguraciÃ³n ajustable** del nÃºmero de fuentes consultadas (1-10)
- ğŸ¨ **Interfaz moderna** con paneles colapsables y diseÃ±o responsivo

## ğŸ—ï¸ Arquitectura TÃ©cnica

```
â”Œâ”€ Interface (Gradio) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chat UI + Paneles de Fuentes                â”‚
â”œâ”€ RAG Pipeline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Query â†’ Embedding (ModernBERT)           â”‚
â”‚ 2. Vector Search (DuckDB + VSS)             â”‚
â”‚ 3. Context Assembly                         â”‚
â”‚ 4. LLM Generation (Gemini/OpenAI/Claude)    â”‚
â”œâ”€ Data Layer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ DuckDB + VSS Extension                      â”‚
â”‚ Embeddings: 768-dim vectors                 â”‚
â”‚ Documents: DOF metadata + text chunks       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Stack TecnolÃ³gico

- **Frontend**: Gradio Blocks con ChatInterface nativa
- **Vector DB**: DuckDB con extensiÃ³n VSS (Vector Similarity Search)
- **Embeddings**: ModernBERT (768 dimensiones)
- **LLM**: Gemini 2.0 Flash (por defecto), OpenAI GPT-4o-mini, Claude 3.5 Sonnet, Ollama
- **Processing**: Python con arquitectura modular

## ğŸš€ Inicio RÃ¡pido

### 1. Prerrequisitos
- Python 3.12+
- Base de datos DOF creada (desde proyecto principal)
- API key de al menos un proveedor LLM

### 2. InstalaciÃ³n de Dependencias
```bash
# Instalar dependencias con uv
uv add openai
uv add python-dotenv
uv add duckdb
uv add "gradio<=5.34.2"
uv add sentence-transformers
```

**Nota importante**: Se requiere Gradio versiÃ³n 5.34.2 o inferior debido a problemas de compatibilidad con versiones mÃ¡s recientes.

### 3. ConfiguraciÃ³n
```bash
# Desde la raÃ­z del proyecto dof-rag
cd chatbot_gradio

# Crear .env en la raÃ­z del proyecto
echo "GEMINI_API_KEY=tu_api_key_aqui" >> ../.env
```

### 4. Ejecutar
```bash
python app.py
# URL: http://localhost:8888
```

## âš™ï¸ ConfiguraciÃ³n de LLM

### Proveedores Soportados
| Proveedor | Variable | Modelo | LÃ­mite/min |
|-----------|----------|--------|------------|
| **Gemini** (default) | `GEMINI_API_KEY` | gemini-2.0-flash | 15 |
| OpenAI | `OPENAI_API_KEY` | gpt-4o-mini | 10 |
| Anthropic | `ANTHROPIC_API_KEY` | claude-3-5-sonnet | 5 |
| Ollama | (local) | llama3.1 | âˆ |

Configura en `.env` en la **raÃ­z del proyecto**:
```env
GEMINI_API_KEY=tu_gemini_key
OPENAI_API_KEY=sk-proj-...
ANTHROPIC_API_KEY=sk-ant-api03-...
```

## ğŸ¯ Casos de Uso

- **InvestigaciÃ³n legal**: BÃºsqueda de decretos, leyes y regulaciones especÃ­ficas
- **AnÃ¡lisis normativo**: Consulta de cambios en polÃ­ticas pÃºblicas
- **Estudios acadÃ©micos**: InvestigaciÃ³n en documentos oficiales histÃ³ricos
- **ConsultorÃ­a**: VerificaciÃ³n rÃ¡pida de informaciÃ³n gubernamental

## ï¿½ Para Desarrolladores

### Estructura Modular
```
config/     â†’ ConfiguraciÃ³n centralizada
core/       â†’ LÃ³gica RAG (database, embeddings, llm, pipeline)
interface/  â†’ UI components (chat, rendering)
```

### Logs
- Consola: Nivel INFO
- Archivo: `chatbot_gradio.log`

### Extensibilidad
- Agregar nuevos proveedores LLM en `core/llm_client.py`
- Personalizar UI en `interface/chat_ui.py`
- Modificar procesamiento en `core/rag_pipeline.py`

---

**Nota**: Este sistema es solo para **consulta**. Para actualizar la base de datos con nuevos documentos DOF, utiliza las herramientas del proyecto principal `dof-rag`.